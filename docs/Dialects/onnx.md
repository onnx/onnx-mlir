<!-- Autogenerated by mlir-tblgen; don't manually edit -->
### `onnx.BatchNormalizationInferenceMode` (ONNXBatchNormalizationInferenceModeOp)

_ONNX BatchNormalization operation in test mode_

Carries out batch normalization as described in the paper
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
there are multiple cases for the number of outputs, which we list below:

Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)"

For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
This operator has **optional** inputs/outputs. See [the doc](IR.md)
for more details about the representation of optional arguments.
An empty string may be used in the place of an actual argument's name to
indicate a missing argument. Trailing optional arguments (those not followed
by an argument that is present) may also be simply omitted.

This operation is not part of the standard and was added to assist onnx-mlir.

Traits: AlwaysSpeculatableImplTrait

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), ShapeHelperOpInterface, ShapeInferenceOpInterface

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>epsilon</code></td><td>::mlir::FloatAttr</td><td>32-bit float attribute</td></tr>
<tr><td><code>momentum</code></td><td>::mlir::FloatAttr</td><td>32-bit float attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `X` | memref of any type values or tensor of any type values
| `scale` | memref of any type values or tensor of any type values
| `B` | memref of any type values or tensor of any type values
| `mean` | memref of any type values or tensor of any type values
| `var` | memref of any type values or tensor of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
| `o_Y` | memref of any type values or tensor of any type values

### `onnx.ConcatShapeTranspose` (ONNXConcatShapeTransposeOp)

_ONNX merged operation_

Merge the following sequence of ops into one op
v1 = onnx.concat
v2 = onnx.shape(v1)
v3 = onnx.transpose(v1)

This operation is not part of the standard and was added to assist onnx-mlir.

Traits: AlwaysSpeculatableImplTrait

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), ShapeHelperOpInterface, ShapeInferenceOpInterface

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>axis</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
<tr><td><code>end</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
<tr><td><code>start</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
<tr><td><code>perm</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `inputs` | variadic of tensor of 8-bit unsigned integer values or tensor of 16-bit unsigned integer values or tensor of 32-bit unsigned integer values or tensor of 64-bit unsigned integer values or tensor of 8-bit signless integer values or tensor of 16-bit signless integer values or tensor of 32-bit signless integer values or tensor of 64-bit signless integer values or tensor of bfloat16 type values or tensor of 16-bit float values or tensor of 32-bit float values or tensor of 64-bit float values or tensor of string type values or tensor of 1-bit signless integer values or tensor of complex type with 32-bit float elements values or tensor of complex type with 64-bit float elements values

#### Results:

| Result | Description |
| :----: | ----------- |
| `shape` | tensor of 64-bit signless integer values
| `transposed` | tensor of 8-bit unsigned integer values or tensor of 16-bit unsigned integer values or tensor of 32-bit unsigned integer values or tensor of 64-bit unsigned integer values or tensor of 8-bit signless integer values or tensor of 16-bit signless integer values or tensor of 32-bit signless integer values or tensor of 64-bit signless integer values or tensor of bfloat16 type values or tensor of 16-bit float values or tensor of 32-bit float values or tensor of 64-bit float values or tensor of string type values or tensor of 1-bit signless integer values or tensor of complex type with 32-bit float elements values or tensor of complex type with 64-bit float elements values

### `onnx.Custom` (ONNXCustomOp)

_ONNX Custom operation_

CustomOp is not an Op defined in onnx standard and was added to support
extention of Op that can be transformed or finally call a user-defined
external function."

It allows for calling a user-defined operation, with a single required
attribute being a string that names the operation. Other inputs are passed
to the user operation.

The number of inputs and outputs can vary.

NoneType is allowed for both input and output, as the CustomOp may require
a fixed number of inputs/outputs for the external function call.

In addition to the values passed to the user-defined operation, certain
attributes are introduced to facilitate the analysis and transformation of
CustomOp.

Since the compiler does not define the semantics of CustomOp, onnx-mlir
cannot infer the shape of its output. Consequently, specific attributes are
introduced to specify how shape inference should be performed on a CustomOp.
These attributes are:
  'inputs_for_infer':
       Optional. The index of inputs used for shape inference.
       The value of index should be [0, the number of inputs).
       If not specified, all the inputs of the CustomOp will be used for
       shape inference.
  'shape_infer_pattern':
       Optional. Specify how to propagate the shape info from the inputs
       (may be limited by inputs_for_infer) to output. Current supported
       patterns are `SameAs`, `MDBroadcast`.
  'output_element_type':
       Optional. The element type for the output tensor. If not specified,
       follow the shape infer pattern behavior. Usually the element type of
       the first input is used.
Each instance of CustomOp can have its own attributes for shape inference,
allowing for customization. However, CustomOps with the same function_name
typically behave similarly in terms of shape inference, and therefore have
the same attributes.

The existing shape inference patterns for ONNX ops are reused for CustomOp,
with the polymorphism in shape inference based on its attribute values.
Due to the current implementation for ONNX Ops, a CustomOp with specified
shape inference attributes supports only a single output, rather than
variadic outputs.

When attributes for shape inference are not provided, the shape inference
for CustomOp will simply pass through.

All of these additional attributes are optional, designed to be less
intrusive. The .mlir file can remain the same when a new attribute is
added.

Traits: AlwaysSpeculatableImplTrait

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), ShapeHelperOpInterface, ShapeInferenceOpInterface

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>function_name</code></td><td>::mlir::StringAttr</td><td>string attribute</td></tr>
<tr><td><code>output_element_type</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr>
<tr><td><code>shape_infer_pattern</code></td><td>::mlir::StringAttr</td><td>string attribute</td></tr>
<tr><td><code>inputs_for_infer</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `inputs` | variadic of tensor of any type values or memref of any type values or none type

#### Results:

| Result | Description |
| :----: | ----------- |
| `outputs` | variadic of tensor of any type values or memref of any type values or none type

### `onnx.DimGroup` (ONNXDimGroupOp)

_ONNX dimension group operation._

This operation is to link a compile-time unknown dimension of a Tensor
to a group id. Two dimensions that have the same group id are expected
to be equal at runtime.

```
"onnx.DimGroup"(%tensor) {axis = 0 : si64, group_id = 1: si64} : (tensor<?x3x5xf32>) -> ()
```

`axis` identifies the dimension position in the tensor.

`group_id` identifies the group id of the dimension. It is non-negative.
Value -1 for `group_id` means the dimension does not belong to any group.

This operation is currently used in the pass `--onnx-dim-analysis`
for testing the unknown dimension analysis class.

This operation is not part of the standard and was added to assist onnx-mlir.

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>axis</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
<tr><td><code>group_id</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `data` | tensor of 8-bit unsigned integer values or tensor of 16-bit unsigned integer values or tensor of 32-bit unsigned integer values or tensor of 64-bit unsigned integer values or tensor of 8-bit signless integer values or tensor of 16-bit signless integer values or tensor of 32-bit signless integer values or tensor of 64-bit signless integer values or tensor of bfloat16 type values or tensor of 16-bit float values or tensor of 32-bit float values or tensor of 64-bit float values or tensor of string type values or tensor of 1-bit signless integer values or tensor of complex type with 32-bit float elements values or tensor of complex type with 64-bit float elements values

### `onnx.Dim` (ONNXDimOp)

_ONNX dimensions operation._

This operation is to obtain the dimension of a Tensor;

```
"onnx.Dim"(%tensor) {axis = 0 : si64} : (tensor<?x3x5xf32>) -> tensor<1xi64>
```

The axis identifies the dimension within the shape which is going to be obtained.

This operation is not part of the standard and was added to assist onnx-mlir.

Traits: AlwaysSpeculatableImplTrait

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), ShapeHelperOpInterface, ShapeInferenceOpInterface

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>axis</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `data` | tensor of 8-bit unsigned integer values or tensor of 16-bit unsigned integer values or tensor of 32-bit unsigned integer values or tensor of 64-bit unsigned integer values or tensor of 8-bit signless integer values or tensor of 16-bit signless integer values or tensor of 32-bit signless integer values or tensor of 64-bit signless integer values or tensor of bfloat16 type values or tensor of 16-bit float values or tensor of 32-bit float values or tensor of 64-bit float values or tensor of string type values or tensor of 1-bit signless integer values or tensor of complex type with 32-bit float elements values or tensor of complex type with 64-bit float elements values

#### Results:

| Result | Description |
| :----: | ----------- |
| `dim` | tensor of 64-bit signless integer values

### `onnx.EntryPoint` (ONNXEntryPointOp)

_Indicate ONNX entry point_

The "onnx.EntryPoint" function indicates the main entry point of ONNX model.

This operation is not part of the standard and was added to assist onnx-mlir.

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>func</code></td><td>::mlir::SymbolRefAttr</td><td>symbol reference attribute</td></tr>
</table>

### `onnx.LayoutTransform` (ONNXLayoutTransformOp)

_An operation that transforms data between different layout formats_

An operation that transforms a tensor from a layout to another layout. 
A layout is defined by an attribute, i.e. `target_layout`, which allows this
operation work with an arbitrary layout (e.g. a layout used for accelerators).

`target_layout` is optional. If it is not given, the input tensor will be
transformed to a normal tensor that does not have layout.

If `target_layout` is the same as the input's layout, this operation will
become an no-op by canonicalization. 

The input and output tensors must have the same shape.

This operation is not part of the standard and was added to assist onnx-mlir.

Traits: AlwaysSpeculatableImplTrait

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), ShapeHelperOpInterface, ShapeInferenceOpInterface

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>target_layout</code></td><td>::mlir::Attribute</td><td>layout attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `data` | tensor of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
| `output` | tensor of 16-bit float or 32-bit float values

### `onnx.MaxPoolSingleOut` (ONNXMaxPoolSingleOutOp)

_ONNX MaxPool operation with a single output._

ONNX MaxPool operation with a single output.
See ONNXMaxPoolOp for a full description of the MaxPool semantics.

This operation is not part of the standard and was added to assist onnx-mlir.

Traits: AlwaysSpeculatableImplTrait

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), ShapeHelperOpInterface, ShapeInferenceOpInterface

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>auto_pad</code></td><td>::mlir::StringAttr</td><td>string attribute</td></tr>
<tr><td><code>ceil_mode</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
<tr><td><code>dilations</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr>
<tr><td><code>kernel_shape</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr>
<tr><td><code>pads</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr>
<tr><td><code>storage_order</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
<tr><td><code>strides</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `X` | memref of any type values or tensor of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
| `o_Y` | memref of any type values or tensor of any type values

### `onnx.NoValue` (ONNXNoneOp)

_An operation representing the absence of a value._

This operation can be used to represent the absence of a value. It is typically
used as an argument to operators that have optional parameters.

Example:
```MLIR
  %cst = "onnx.NoValue"() {value} : () -> none
  %0, %1 = "onnx.Split"(%arg0, %cst) { axis=1 : si64 } : (tensor<?xf32>, none) -> (tensor<*xf32>, tensor<*xf32>)
```

This operation is not part of the standard and was added to assist onnx-mlir.

Traits: AlwaysSpeculatableImplTrait, ConstantLike

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface)

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>value</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr>
</table>

#### Results:

| Result | Description |
| :----: | ----------- |
| `none_val` | none type

### `onnx.PrintSignature` (ONNXPrintSignatureOp)

_ONNX Op to print type signature of its input operands_

Print type signature of the op's input operands. This operation is introduced early
so as to preserve the name of the original ONNX op.

This operation is not part of the standard and was added to assist onnx-mlir.

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>op_name</code></td><td>::mlir::StringAttr</td><td>string attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `input` | variadic of tensor of any type values or none type

### `onnx.RMSLayerNormalization` (ONNXRMSLayerNormalizationOp)

_ONNX RMSLayerNormalization operation_

This is RMS layer normalization defined in ONNX as function.
      The overall computation can be split into two stages.
      The first stage is an approximate standardization, which makes the
      normalized elements have zero mean and unit variances.
      See Equation (4) in [this paper](https://arxiv.org/pdf/1910.07467.pdf).
      The computation required by standardization can be
      described by the following equations.
      ```
      DD = Mul(X, X)
      Var = ReduceMean<axes=normalized_axes>(DD)
      VarEps = Add(Var, epsilon)
      StdDev = Sqrt(VarEps)
      InvStdDev = Reciprocal(StdDev)
      Normalized = Mul(X, InvStdDev)
      ```
      where `normalized_axes` is `[axis, ..., rank of X - 1]`.
      The variables `Var` and `StdDev` stand for approximate variance and
      standard deviation, respectively.
      Depending on `stash_type` attribute, the actual computation
      must happen in different floating-point precision.
      For example, if `stash_type` is 1, this operator casts
      all input variables to 32-bit float, perform the computation, and
      finally cast `Normalized` back to the original type of `X`.
      The second stage then scales and shifts the outcome of the
      first stage using
      ```
      NormalizedScaled = Mul(Normalized, Scale)
      Y = Add(NormalizedScaled, B)
      ```
      The second stage doesn't depends on `stash_type`.
      All equations are in [this syntax](https://github.com/onnx/onnx/blob/main/docs/Syntax.md).
      The same variable (i.e., input, output, and attribute) uses
      the same name in the equations above and this operator's definition.
      Let `d[i]` indicate the i-th dimension of `X`.
      If `X`'s shape is `[d[0], ..., d[axis-1], d[axis], ..., d[rank-1]]`,
      the shape of `Mean` and `InvStdDev` is `[d[0], ..., d[axis-1], 1, ..., 1]`.
      `Y` and `X` have the same shape.

Traits: AlwaysSpeculatableImplTrait

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), ShapeHelperOpInterface, ShapeInferenceOpInterface

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>axis</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
<tr><td><code>epsilon</code></td><td>::mlir::FloatAttr</td><td>32-bit float attribute</td></tr>
<tr><td><code>stash_type</code></td><td>::mlir::IntegerAttr</td><td>64-bit signed integer attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `X` | tensor of 16-bit float values or tensor of 32-bit float values or tensor of 64-bit float values or tensor of bfloat16 type values
| `Scale` | tensor of 16-bit float values or tensor of 32-bit float values or tensor of 64-bit float values or tensor of bfloat16 type values
| `B` | tensor of 16-bit float values or tensor of 32-bit float values or tensor of 64-bit float values or tensor of bfloat16 type values or none type

#### Results:

| Result | Description |
| :----: | ----------- |
| `Y` | tensor of 16-bit float values or tensor of 32-bit float values or tensor of 64-bit float values or tensor of bfloat16 type values
| `InvStdDev` | tensor of 32-bit float values or tensor of bfloat16 type values or none type

### `onnx.Return` (ONNXReturnOp)

_Function return operation_


Syntax:

```
operation ::= `onnx.Return` attr-dict ($operands^ `:` type($operands))?
```

The `onnx.Return` operation represents a return operation within a function.
The operation takes variable number of operands and produces no results.
The operand number and types must match the signature of the function
that contains the operation, with the exception that shaped types may have
more specific shapes than the function signature result types, which allows
rewrites of defining ops of operands to make their result shapes more specific.
This operation terminates a func::FuncOp in the ONNX dialect and is replaced
by func::ReturnOp in StandardFuncReturnPass before lowering to Krnl or other
dialects.

Traits: AlwaysSpeculatableImplTrait, HasParent<func::FuncOp>, ReturnLike, Terminator

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), RegionBranchTerminatorOpInterface

Effects: MemoryEffects::Effect{}

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `operands` | variadic of any type

### `onnx.ShapeTransform` (ONNXShapeTransformOp)

_ONNX Element-wise shape transformation operation_

This operator transforms a tensor into another tensor whose shape is changed
by a given affine map. This is elemement-wise transformation, so each element
in the input will be copied to an element in the output via the affine map.
The affine map must be bijective.

For example, the following code is using `onnx.ShapeTransform` to reshape
a tensor from 2D to 4D.
```mlir
#reshape = affine_map(d0, d1) -> (d0/32, d0%32, d1/64, d1%64)
%Y = onnx.ShapeTransform(%arg0) {index_map = #reshape} :  (tensor<128x128xf32>) -> tensor<4x32x2x64xf32>
```

`onnx.ShapeTransform` will be finally materialized into an `affine.for` via
lowering to `krnl` dialect, e.g.
```mlir
%alloc = memref.alloc() {alignment = 16 : i64} : memref<4x32x2x64xf32>
affine.for %arg1 = 0 to 128 {
  affine.for %arg2 = 0 to 128 {
    %0 = affine.load %arg0[%arg1, %arg2] : memref< 128x128xf32 >
    affine.store %0, %alloc[%arg1 / 32, %arg1 % 32, %arg2 / 64, %arg2 % 64] : memref<4x32x2x64xf32>
  }
}
```

When being canonicalized, ShapeTransform operations are composed into
a new ShapeTransform operation by composing their affine maps.

At this moment, this operation only supports static dimensions.

This operation is not part of the standard and was added to assist onnx-mlir.

Traits: AlwaysSpeculatableImplTrait

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), ShapeHelperOpInterface, ShapeInferenceOpInterface

Effects: MemoryEffects::Effect{}

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>index_map</code></td><td>::mlir::AffineMapAttr</td><td>AffineMap attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `input` | tensor of 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
| `output` | tensor of 32-bit float values

### `onnx.Yield` (ONNXYieldOp)

_ONNX yield operation_


Syntax:

```
operation ::= `onnx.Yield` attr-dict ($operands^ `:` type($operands))?
```

The `onnx.Yield` operation represents a yield operation within an ONNX subgraph.
The operation takes variable number of operands and produces no results.

This operation is not part of the standard and was added to assist onnx-mlir.
It terminates a ONNXLoop/Scan/IfOp region.

Traits: AlwaysSpeculatableImplTrait, ReturnLike, Terminator

Interfaces: ConditionallySpeculatable, NoMemoryEffect (MemoryEffectOpInterface), RegionBranchTerminatorOpInterface

Effects: MemoryEffects::Effect{}

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `operands` | variadic of any type

