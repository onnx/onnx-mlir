//===--- ONNXOps.td -- ONNX Dialect Operation Definitions ----*- tablegen -===//
//
// Copyright 2019-2020 The IBM Research Authors
//
// =============================================================================
//
// Defines ONNX Dialect operations.
//
//===----------------------------------------------------------------------===//

#ifdef ONNX_OPS
#else
#define ONNX_OPS

#ifdef OP_BASE
#else
include "mlir/IR/OpBase.td"
#endif // OP_BASE

def StringType : Type<CPred<"$_self.isa<StringType>()">, "stirng type">;

def IsSeqTypePred : CPred<"$_self.isa<SeqType>()">;

class SeqOf<list<Type> allowedTypes> : 
  ContainerType<AnyTypeOf<allowedTypes>, IsSeqTypePred,
                "$_self.cast<SeqType>().getElementType()",  "SeqType">;

#ifdef SHAPE_INFERENCE_INTERFACE
#else
include "src/Interface/ShapeInferenceInterface.td"
#endif // SHAPE_INFERENCE_INTERFACE

#ifdef PROMOTABLE_CONST_OPERANDS_OP_INTERFACE
#else
include "src/Interface/PromotableConstOperandsOpInterface.td"
#endif // PROMOTABLE_CONST_OPERANDS_OP_INTERFACE

#ifdef RESULT_TYPE_INFERENCE_OP_INTERFACE
#else
include "src/Interface/ResultTypeInferenceOpInterface.td"
#endif // RESULT_TYPE_INFERENCE_OP_INTERFACE

def ONNX_Dialect : Dialect {
  let name = "onnx";
  let cppNamespace = "";
}

// Base class for ONNX dialect operations. This operation inherits from the base
// `Op` class in OpBase.td, and provides:
//   * The parent dialect of the operation.
//   * The mnemonic for the operation, or the name without the dialect prefix.
//   * A list of traits for the operation.
class ONNX_Op<string mnemonic, list<OpTrait> traits = []> :
    Op<ONNX_Dialect, mnemonic, traits> ;

//===----------------------------------------------------------------------===//
// ONNX Operations
//===----------------------------------------------------------------------===//

//the tablegen code onnxop.in is generated with gen_doc.py
//clone and install onnx
//   git clone --recursive https://github.com/onnx/onnx.git
// set up env for anaconda3 and for ONNX MLIR (BOOSTROOT, cmake, gcc ...)
//   cd onnx
//install onnx
//  CC=gcc CXX=g++ pip install -e .
//run the script
//  python onnx/defs/gen_doc.py
//result is in docs/onnx_ops.td.inc
//current limitations:
// 1. Attributes are not processed
// 2. output type inference not implemented except Add
// 3. Type Attribute: 'optional' and 'Variadic hetergeneous' are ignored
// 4. type of string, complex64 and complex128 for input/output are ignored 
// 5. unsigned int are treated as signed one

include "mlir/Interfaces/SideEffectInterfaces.td"
include "src/Dialect/ONNX/ONNXOps.td.inc"

// Indicate entry point functions of ONNX graph.
def ONNXEntryPointOp: ONNX_Op<"EntryPoint"> {
  let summary = "Indicate ONNX entry point";
  let description = [{
    The "onnx.EntryPoint" function indicates the main entry point of ONNX model.
  }];

  let builders = [OpBuilder<[{OpBuilder &builder, OperationState &state,
                             FuncOp function, int numInputs, int numOutputs}]>];

  let extraClassDeclaration = [{
    static ONNXEntryPointOp create(Location location, FuncOp& func,
                                   int numInputs, int numOutputs);

    static StringRef getEntryPointFuncAttrName() { return "func"; }
    static StringRef getNumInputsAttrName() { return "numInputs"; }
    static StringRef getNumOutputsAttrName() { return "numOutputs"; }
  }];
}

//===----------------------------------------------------------------------===//
// ONNX Operations for handling optional arguments
//===----------------------------------------------------------------------===//

// To allow pattern matching on operations with optional arguments/outputs we
// implement variants of the original ONNX dialect operations. The ONNX
// operations automatically generated by the `gen_doc.py` script and included
// in the `onnxop.inc` file have all optional arguments and outputs present.
// In the operations below we include the variants with missing operands
// or outputs. This decision affects only ONNX operations with optional
// arguments not ONNX operations with variadic operands.

def ONNXMaxPoolSingleOutOp: ONNX_Op<"MaxPoolSingleOut",
    [NoSideEffect, DeclareOpInterfaceMethods<ShapeInferenceOpInterface>]> {
  let summary = "ONNX MaxPool operation with a single output.";
  let description = [{
    "ONNX MaxPool operation with a single output."
    "See ONNXMaxPoolOp for a full description of the MaxPool semantics."
  }];
  let arguments = (ins AnyTypeOf<[AnyMemRef, AnyTensor]>:$X,
           DefaultValuedAttr<StrAttr, "NOTSET">:$auto_pad,
           DefaultValuedAttr<I64Attr, "0">:$ceil_mode,
           OptionalAttr<I64ArrayAttr>:$dilations,
           DefaultValuedAttr<I64ArrayAttr, "{}">:$kernel_shape,
           OptionalAttr<I64ArrayAttr>:$pads,
           DefaultValuedAttr<I64Attr, "0">:$storage_order,
           OptionalAttr<I64ArrayAttr>:$strides);
  let results = (outs AnyTypeOf<[AnyMemRef, AnyTensor]>:$o_Y);
  let extraClassDeclaration = [{
    static int getNumberOfOperands() {
      return 1;
    }
    static int getNumberOfResults() {
      return 1;
    }
    static std::vector<int> getTypeMap() {
      return {20};
    }
  }];
}

def ONNXBatchNormalizationTestModeOp: ONNX_Op<"BatchNormalizationTestMode",
    [NoSideEffect, DeclareOpInterfaceMethods<ShapeInferenceOpInterface>]> {
  let summary = "ONNX BatchNormalization operation in test mode";
  let hasCanonicalizer = 1;
  let description = [{
    "Carries out batch normalization as described in the paper"
    "https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,"
    "there are multiple cases for the number of outputs, which we list below:"
    ""
    "Output case #1: Y, mean, var, saved_mean, saved_var (training mode)"
    "Output case #2: Y (test mode)"
    ""
    "For previous (depreciated) non-spatial cases, implementors are suggested"
    "to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op."
    "This operator has **optional** inputs/outputs. See [the doc](IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted."
  }];
  let arguments = (ins AnyTypeOf<[AnyMemRef, AnyTensor]>:$X,
           AnyTypeOf<[AnyMemRef, AnyTensor]>:$scale,
           AnyTypeOf<[AnyMemRef, AnyTensor]>:$B,
           AnyTypeOf<[AnyMemRef, AnyTensor]>:$mean,
           AnyTypeOf<[AnyMemRef, AnyTensor]>:$var,
           DefaultValuedAttr<F32Attr, "1e-05">:$epsilon,
           DefaultValuedAttr<F32Attr, "0.9">:$momentum);
  let results = (outs AnyTypeOf<[AnyMemRef, AnyTensor]>:$o_Y);
  let extraClassDeclaration = [{
    static int getNumberOfOperands() {
      return 5;
    }
    static int getNumberOfResults() {
      return 1;
    }
    static std::vector<int> getTypeMap() {
      return {20};
    }
  }];
}

def ONNXPadConstantValueOp : ONNX_Op<"PadConstantValue",
    [NoSideEffect ]> {
  let summary = "ONNX Pad operation with constant padding value";
  let hasCanonicalizer = 1;
  let description = [{ "this operation is introduced to handle situation"
    " in which the padding value is a constant.
    " The value will become an attribute."
    "This operation is also used to handle the optional value input is missing and the default value 0."
    "is used."
   }];
  let arguments = (ins AnyTypeOf<[AnyMemRef, AnyTensor]>:$data,
           AnyTypeOf<[AnyMemRef, AnyTensor]>:$pads,
           DefaultValuedAttr<F32Attr, "0.0">:$constant_value,
           DefaultValuedAttr<StrAttr, "constant">:$mode);
  let results = (outs AnyTypeOf<[AnyMemRef, AnyTensor]>:$output);
  let extraClassDeclaration = [{
    static int getNumberOfOperands() {
      return 1;
    }
    static int getNumberOfResults() {
      return 1;
    }
    static std::vector<int> getTypeMap() {
      return {0};
    }
  }];
}

def ONNXPadConstantPadOp : ONNX_Op<"PadConstantPad",
    [NoSideEffect, DeclareOpInterfaceMethods<ShapeInferenceOpInterface> ]> {
  let summary = "ONNX Pad operation with constant padding value";
  let description = [{ "this operation is introduced to handle situation"
    " in which the padding value and padding are constants"
    "They will become attributes."
   }];
  let arguments = (ins AnyTypeOf<[AnyMemRef, AnyTensor]>:$data,
           AnyTypeOf<[AnyMemRef, AnyTensor]>:$constant_value,
           I64ArrayAttr:$pads,
           DefaultValuedAttr<StrAttr, "constant">:$mode);
  let results = (outs AnyTypeOf<[AnyMemRef, AnyTensor]>:$output);
  let extraClassDeclaration = [{
    static int getNumberOfOperands() {
      return 1;
    }
    static int getNumberOfResults() {
      return 1;
    }
    static std::vector<int> getTypeMap() {
      return {0};
    }
  }];
}

def ONNXPadConstantValuePadOp : ONNX_Op<"PadConstantValuePad",
    [NoSideEffect, DeclareOpInterfaceMethods<ShapeInferenceOpInterface> ]> {
  let summary = "ONNX Pad operation with constant padding value";
  let description = [{ "this operation is introduced to handle situation"
    " in which the padding value and padding are constants"
    "They will become attributes."
   }];
  let arguments = (ins AnyTypeOf<[AnyMemRef, AnyTensor]>:$data,
           I64ArrayAttr:$pads,
           DefaultValuedAttr<F32Attr, "0.0">:$constant_value,
           DefaultValuedAttr<StrAttr, "constant">:$mode);
  let results = (outs AnyTypeOf<[AnyMemRef, AnyTensor]>:$output);
  // A build method with the result type deduction.
  let builders = [OpBuilder<"OpBuilder &builder, OperationState &state, "
                            "Value data, ArrayAttr pads, "
                            "FloatAttr constant_value, StringAttr mode">];
  let extraClassDeclaration = [{
    static int getNumberOfOperands() {
      return 1;
    }
    static int getNumberOfResults() {
      return 1;
    }
    static std::vector<int> getTypeMap() {
      return {0};
    }
  }];
}

#endif // ONNX_OPS
