---
layout: default
---
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>onnx-mlir: ONNX-MLIR Runtime API documentation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">onnx-mlir
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">ONNX-MLIR Runtime API documentation </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="intro_sec"></a>
Introduction</h1>
<p>ONNX-MLIR project comes with an executable <code>onnx-mlir</code> capable of compiling onnx models to a shared library. In this documentation, we demonstrate how to interact programmatically with the compiled shared library using ONNX-MLIR's Runtime API.</p>
<h1><a class="anchor" id="c-runtime-api"></a>
C Runtime API</h1>
<h2><a class="anchor" id="data-structures"></a>
Data Structures</h2>
<p><code>OMTensor</code> is the data structure used to describe the runtime information (rank, shape, data type, etc) associated with a tensor input or output.</p>
<p><code>OMTensorList</code> is the data structure used to hold a list of pointers to OMTensor so that they can be passed into and out of the compiled model as inputs and outputs.</p>
<p><code>OMEntryPoint</code> is the data structure used to return all entry point names in a model. These entry point names are the symbols of the inference functions in the model.</p>
<p><code>OMSignature</code> is the data structure used to return the output signature of the given entry point as a JSON string.</p>
<h2><a class="anchor" id="model-entry-point-signature"></a>
Model Entry Point Signature</h2>
<p>All compiled models will have the same exact C function signature equivalent to:</p>
<div class="fragment"><div class="line">OMTensorList* run_main_graph(OMTensorList*);</div>
</div><!-- fragment --><p>Intuitively, the model takes a list of tensors as input and returns a list of tensors as output.</p>
<h2><a class="anchor" id="invoke-models-using-c-runtime-api"></a>
Invoke Models Using C Runtime</h2>
<p>API</p>
<p>We demonstrate using the API functions to run a simple ONNX model consisting of an add operation. To create such an onnx model, use this <a href="gen_add_onnx.py" target="_blank"><b>python script</b></a></p>
<p>To compile the above model, run <code>onnx-mlir add.onnx</code> and a binary library "add.so" should appear. We can use the following C code to call into the compiled function computing the sum of two inputs:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_onnx_mlir_runtime_8h.html">OnnxMlirRuntime.h</a>&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;stdio.h&gt;</span></div>
<div class="line"> </div>
<div class="line">OMTensorList *run_main_graph(OMTensorList *);</div>
<div class="line"> </div>
<div class="line">OMTensorList *create_input_list() {</div>
<div class="line">  <span class="comment">// Shared shape &amp; rank.</span></div>
<div class="line">  int64_t shape[] = {3, 2};</div>
<div class="line">  int64_t num_elements = shape[0] * shape[1];</div>
<div class="line">  int64_t rank = 2;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Construct float arrays filled with 1s or 2s.</span></div>
<div class="line">  <span class="keywordtype">float</span> *x1Data = (<span class="keywordtype">float</span> *)malloc(<span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * num_elements);</div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; num_elements; i++)</div>
<div class="line">    x1Data[i] = 1.0;</div>
<div class="line">  <span class="keywordtype">float</span> *x2Data = (<span class="keywordtype">float</span> *)malloc(<span class="keyword">sizeof</span>(<span class="keywordtype">float</span>) * num_elements);</div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; num_elements; i++)</div>
<div class="line">    x2Data[i] = 2.0;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Use omTensorCreateWithOwnership &quot;true&quot; so float arrays are automatically</span></div>
<div class="line">  <span class="comment">// freed when the Tensors are destroyed.</span></div>
<div class="line">  OMTensor *x1 = omTensorCreateWithOwnership(x1Data, shape, rank, ONNX_TYPE_FLOAT, <span class="keyword">true</span>);</div>
<div class="line">  OMTensor *x2 = omTensorCreateWithOwnership(x2Data, shape, rank, ONNX_TYPE_FLOAT, <span class="keyword">true</span>);</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Construct a TensorList using the Tensors</span></div>
<div class="line">  OMTensor *list[2] = {x1, x2};</div>
<div class="line">  <span class="keywordflow">return</span> omTensorListCreate(list, 2);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> main() {</div>
<div class="line">  <span class="comment">// Generate input TensorList</span></div>
<div class="line">  OMTensorList *input_list = create_input_list();</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Call the compiled onnx model function.</span></div>
<div class="line">  OMTensorList *output_list = run_main_graph(input_list);</div>
<div class="line">  <span class="keywordflow">if</span> (!output_list) {</div>
<div class="line">    <span class="comment">// May inspect errno to get info about the error.</span></div>
<div class="line">    <span class="keywordflow">return</span> 1;</div>
<div class="line">  }</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Get the first tensor from output list.</span></div>
<div class="line">  OMTensor *y = omTensorListGetOmtByIndex(output_list, 0);</div>
<div class="line">  <span class="keywordtype">float</span> *outputPtr = (<span class="keywordtype">float</span> *) omTensorGetDataPtr(y);</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Print its content, should be all 3.</span></div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; 6; i++)</div>
<div class="line">    printf(<span class="stringliteral">&quot;%f &quot;</span>, outputPtr[i]);</div>
<div class="line">  printf(<span class="stringliteral">&quot;\n&quot;</span>);</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Destory the list and the tensors inside of it.</span></div>
<div class="line">  <span class="comment">// Use omTensorListDestroyShallow if only want to destroy the list themselves.</span></div>
<div class="line">  omTensorListDestroy(input_list);</div>
<div class="line">  omTensorListDestroy(output_list);</div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
<div class="ttc" id="a_onnx_mlir_runtime_8h_html"><div class="ttname"><a href="_onnx_mlir_runtime_8h.html">OnnxMlirRuntime.h</a></div></div>
</div><!-- fragment --><p>Compile with <code>gcc main.c add.so -o add</code>, you should see an executable <code>add</code> appearing. Run it, and the output should be:</p>
<div class="fragment"><div class="line">3.000000 3.000000 3.000000 3.000000 3.000000 3.000000</div>
</div><!-- fragment --><p> Exactly as it should be.</p>
<h2><a class="anchor" id="freeing-tensor-memory"></a>
Freeing Tensor Memory</h2>
<p>In general, if a caller creates a tensor object (omTensorCreate), they are responsible for deallocating the data buffer separately after the tensor is destroyed. If onnx-mlir creates the tensor (run_main_graph), then the tensor object owns the data buffer and it is freed automatically when the tensor is destroyed.</p>
<p>This default behavior can be changed. When creating a tensor, a user may use omTensorCreateWithOwnership to explicitly set data buffer ownership. Additionally, after a tenor is created, omTensorSetOwning can be used to change the ownership setting.</p>
<p>When omTensorDestroy is called, if the ownership flag is set to "true", then the destruction of the tensor will also free any associated data buffer memory. If the ownership flag is set to "false", then the user is responsible for freeing the data buffer memory after destroying the tensor.</p>
<p>For tensor list objects, when omTensorListDestory is called, omTensorDestory is called on all tensors the list contained. The data buffer of each tensor is freed based on each tensor's ownership setting.</p>
<p>To destroy a TensorList without automatically destorying the tensors it contained, use omTensorListDestroyShallow.</p>
<h2><a class="anchor" id="reference"></a>
Reference</h2>
<p>For full reference to available C Runtime API, refer to <code>include/onnx-mlir/Runtime/OMTensor.h</code> and <code>include/onnx-mlir/Runtime/OMTensorList.h</code>. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
