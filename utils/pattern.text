// mlir2FileCheck.py
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @reduce_min_ch
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<1x32x100x32xbf16>) -> tensor<1x1x1x32xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = tosa.reshape [[PARAM_0_]] {new_shape = array<i64: 1, 32, 3200>} : (tensor<1x32x100x32xbf16>) -> tensor<1x32x3200xbf16>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[VAR_0_]]: tensor<1x32x3200xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "ReduceMin_0",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "ReduceMin_0",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 32 : ui32,
// CHECK-NO-C8:               config.full_height = 1 : ui32,
// CHECK-NO-C8:               config.full_width = 3200 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "C"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_5_:%.+]] = tosa.reshape [[VAR_arg1_]] {new_shape = array<i64: 1, 32, 100, 32>} : (tensor<1x32x3200xbf16>) -> tensor<1x32x100x32xbf16>
// CHECK-NO-C8:             [[VAR_6_:%.+]] = tosa.reduce_min [[VAR_5_]] {
// CHECK-NO-C8:               LayerName = "ReduceMin_0",
// CHECK-NO-C8:               OutputName = "ReduceMin_0",
// CHECK-NO-C8:               axis = 1 : i32} : (tensor<1x32x100x32xbf16>) -> tensor<1x1x100x32xbf16>
// CHECK-NO-C8:             [[VAR_7_:%.+]] = tosa.reshape [[VAR_6_]] {new_shape = array<i64: 1, 1, 3200>} : (tensor<1x1x100x32xbf16>) -> tensor<1x1x3200xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_7_]] : tensor<1x1x3200xbf16>
// CHECK-NO-C8:           } -> tensor<1x1x3200xbf16>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = tosa.reshape [[VAR_1_]] {new_shape = array<i64: 1, 100, 32>} : (tensor<1x1x3200xbf16>) -> tensor<1x100x32xbf16>
// CHECK-NO-C8:           [[VAR_3_:%.+]] = xten_nn.subgraph ([[VAR_arg1_1_:%.+]] = [[VAR_2_]]: tensor<1x100x32xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "ReduceMin_1",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 100 : ui32,
// CHECK-NO-C8:               config.full_height = 1 : ui32,
// CHECK-NO-C8:               config.full_width = 32 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "C"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_5_1_:%.+]] = tosa.reshape [[VAR_arg1_1_]] {new_shape = array<i64: 1, 1, 100, 32>} : (tensor<1x100x32xbf16>) -> tensor<1x1x100x32xbf16>
// CHECK-NO-C8:             [[VAR_6_1_:%.+]] = tosa.reduce_min [[VAR_5_1_]] {OutputName = "ReduceMin_1", axis = 2 : i32} : (tensor<1x1x100x32xbf16>) -> tensor<1x1x1x32xbf16>
// CHECK-NO-C8:             [[VAR_7_1_:%.+]] = tosa.reshape [[VAR_6_1_]] {new_shape = array<i64: 1, 1, 32>} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_7_1_]] : tensor<1x1x32xbf16>
// CHECK-NO-C8:           } -> tensor<1x1x32xbf16>
// CHECK-NO-C8:           [[VAR_4_:%.+]] = tosa.reshape [[VAR_3_]] {new_shape = array<i64: 1, 1, 1, 32>} : (tensor<1x1x32xbf16>) -> tensor<1x1x1x32xbf16>
// CHECK-NO-C8:           return [[VAR_4_]] : tensor<1x1x1x32xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @reduce_min_hw_batch4
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<4x32x100x32xbf16>) -> tensor<4x32x1x1xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = tosa.reshape [[PARAM_0_]] {new_shape = array<i64: 128, 100, 32>} : (tensor<4x32x100x32xbf16>) -> tensor<128x100x32xbf16>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[VAR_0_]]: tensor<128x100x32xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "ReduceMin_0",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "ReduceMin_0",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 100 : ui32,
// CHECK-NO-C8:               config.full_height = 128 : ui32,
// CHECK-NO-C8:               config.full_width = 32 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "C"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_4_:%.+]] = tosa.reshape [[VAR_arg1_]] {new_shape = array<i64: 4, 32, 100, 32>} : (tensor<128x100x32xbf16>) -> tensor<4x32x100x32xbf16>
// CHECK-NO-C8:             [[VAR_5_:%.+]] = tosa.reduce_min [[VAR_4_]] {
// CHECK-NO-C8:               LayerName = "ReduceMin_0",
// CHECK-NO-C8:               OutputName = "ReduceMin_0",
// CHECK-NO-C8:               axis = 2 : i32} : (tensor<4x32x100x32xbf16>) -> tensor<4x32x1x32xbf16>
// CHECK-NO-C8:             [[VAR_6_:%.+]] = tosa.reshape [[VAR_5_]] {new_shape = array<i64: 128, 1, 32>} : (tensor<4x32x1x32xbf16>) -> tensor<128x1x32xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_6_]] : tensor<128x1x32xbf16>
// CHECK-NO-C8:           } -> tensor<128x1x32xbf16>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = xten_nn.subgraph ([[VAR_arg1_1_:%.+]] = [[VAR_1_]]: tensor<128x1x32xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "ReduceMin_1",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 1 : ui32,
// CHECK-NO-C8:               config.full_height = 128 : ui32,
// CHECK-NO-C8:               config.full_width = 32 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "W"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_4_1_:%.+]] = tosa.reshape [[VAR_arg1_1_]] {new_shape = array<i64: 4, 32, 1, 32>} : (tensor<128x1x32xbf16>) -> tensor<4x32x1x32xbf16>
// CHECK-NO-C8:             [[VAR_5_1_:%.+]] = tosa.reduce_min [[VAR_4_1_]] {OutputName = "ReduceMin_1", axis = 3 : i32} : (tensor<4x32x1x32xbf16>) -> tensor<4x32x1x1xbf16>
// CHECK-NO-C8:             [[VAR_6_1_:%.+]] = tosa.reshape [[VAR_5_1_]] {new_shape = array<i64: 128, 1, 1>} : (tensor<4x32x1x1xbf16>) -> tensor<128x1x1xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_6_1_]] : tensor<128x1x1xbf16>
// CHECK-NO-C8:           } -> tensor<128x1x1xbf16>
// CHECK-NO-C8:           [[VAR_3_:%.+]] = tosa.reshape [[VAR_2_]] {new_shape = array<i64: 4, 32, 1, 1>} : (tensor<128x1x1xbf16>) -> tensor<4x32x1x1xbf16>
// CHECK-NO-C8:           return [[VAR_3_]] : tensor<4x32x1x1xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_reduce_min_bf16_annotations
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3xbf16>) -> tensor<1x21x3xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[PARAM_0_]]: tensor<13x21x3xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "LAYERNAME",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "OUTPUTNAME",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 21 : ui32,
// CHECK-NO-C8:               config.full_height = 13 : ui32,
// CHECK-NO-C8:               config.full_width = 3 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "H"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_1_:%.+]] = tosa.reduce_min [[VAR_arg1_]] {
// CHECK-NO-C8:               LayerName = "LAYERNAME",
// CHECK-NO-C8:               OutputName = "OUTPUTNAME",
// CHECK-NO-C8:               axis = 0 : i32} : (tensor<13x21x3xbf16>) -> tensor<1x21x3xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_1_]] : tensor<1x21x3xbf16>
// CHECK-NO-C8:           } -> tensor<1x21x3xbf16>
// CHECK-NO-C8:           return [[VAR_0_]] : tensor<1x21x3xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_bf16_4D
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<1x13x21x3xbf16>) -> tensor<1x1x21x3xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = tosa.reshape [[PARAM_0_]] {new_shape = array<i64: 1, 13, 63>} : (tensor<1x13x21x3xbf16>) -> tensor<1x13x63xbf16>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[VAR_0_]]: tensor<1x13x63xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "LAYERNAME",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "OUTPUTNAME",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 13 : ui32,
// CHECK-NO-C8:               config.full_height = 1 : ui32,
// CHECK-NO-C8:               config.full_width = 63 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "C"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_3_:%.+]] = tosa.reshape [[VAR_arg1_]] {new_shape = array<i64: 1, 13, 21, 3>} : (tensor<1x13x63xbf16>) -> tensor<1x13x21x3xbf16>
// CHECK-NO-C8:             [[VAR_4_:%.+]] = tosa.reduce_min [[VAR_3_]] {
// CHECK-NO-C8:               LayerName = "LAYERNAME",
// CHECK-NO-C8:               OutputName = "OUTPUTNAME",
// CHECK-NO-C8:               axis = 1 : i32} : (tensor<1x13x21x3xbf16>) -> tensor<1x1x21x3xbf16>
// CHECK-NO-C8:             [[VAR_5_:%.+]] = tosa.reshape [[VAR_4_]] {new_shape = array<i64: 1, 1, 63>} : (tensor<1x1x21x3xbf16>) -> tensor<1x1x63xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_5_]] : tensor<1x1x63xbf16>
// CHECK-NO-C8:           } -> tensor<1x1x63xbf16>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = tosa.reshape [[VAR_1_]] {new_shape = array<i64: 1, 1, 21, 3>} : (tensor<1x1x63xbf16>) -> tensor<1x1x21x3xbf16>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<1x1x21x3xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_bf16_2D
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21xbf16>) -> tensor<1x21xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = tosa.reshape [[PARAM_0_]] {new_shape = array<i64: 13, 21, 1>} : (tensor<13x21xbf16>) -> tensor<13x21x1xbf16>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[VAR_0_]]: tensor<13x21x1xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 21 : ui32,
// CHECK-NO-C8:               config.full_height = 13 : ui32,
// CHECK-NO-C8:               config.full_width = 1 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "H"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_3_:%.+]] = tosa.reshape [[VAR_arg1_]] {new_shape = array<i64: 13, 21>} : (tensor<13x21x1xbf16>) -> tensor<13x21xbf16>
// CHECK-NO-C8:             [[VAR_4_:%.+]] = tosa.reduce_min [[VAR_3_]] {axis = 0 : i32} : (tensor<13x21xbf16>) -> tensor<1x21xbf16>
// CHECK-NO-C8:             [[VAR_5_:%.+]] = tosa.reshape [[VAR_4_]] {new_shape = array<i64: 1, 21, 1>} : (tensor<1x21xbf16>) -> tensor<1x21x1xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_5_]] : tensor<1x21x1xbf16>
// CHECK-NO-C8:           } -> tensor<1x21x1xbf16>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = tosa.reshape [[VAR_1_]] {new_shape = array<i64: 1, 21>} : (tensor<1x21x1xbf16>) -> tensor<1x21xbf16>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<1x21xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_bf16_4D_axis_0
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3x4xbf16>) -> tensor<1x21x3x4xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = tosa.reshape [[PARAM_0_]] {new_shape = array<i64: 13, 21, 12>} : (tensor<13x21x3x4xbf16>) -> tensor<13x21x12xbf16>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[VAR_0_]]: tensor<13x21x12xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 21 : ui32,
// CHECK-NO-C8:               config.full_height = 13 : ui32,
// CHECK-NO-C8:               config.full_width = 12 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "H"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_3_:%.+]] = tosa.reshape [[VAR_arg1_]] {new_shape = array<i64: 13, 21, 3, 4>} : (tensor<13x21x12xbf16>) -> tensor<13x21x3x4xbf16>
// CHECK-NO-C8:             [[VAR_4_:%.+]] = tosa.reduce_min [[VAR_3_]] {axis = 0 : i32} : (tensor<13x21x3x4xbf16>) -> tensor<1x21x3x4xbf16>
// CHECK-NO-C8:             [[VAR_5_:%.+]] = tosa.reshape [[VAR_4_]] {new_shape = array<i64: 1, 21, 12>} : (tensor<1x21x3x4xbf16>) -> tensor<1x21x12xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_5_]] : tensor<1x21x12xbf16>
// CHECK-NO-C8:           } -> tensor<1x21x12xbf16>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = tosa.reshape [[VAR_1_]] {new_shape = array<i64: 1, 21, 3, 4>} : (tensor<1x21x12xbf16>) -> tensor<1x21x3x4xbf16>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<1x21x3x4xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_bf16_4D_axis_1
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3x4xbf16>) -> tensor<13x1x3x4xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = tosa.reshape [[PARAM_0_]] {new_shape = array<i64: 13, 21, 12>} : (tensor<13x21x3x4xbf16>) -> tensor<13x21x12xbf16>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[VAR_0_]]: tensor<13x21x12xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 21 : ui32,
// CHECK-NO-C8:               config.full_height = 13 : ui32,
// CHECK-NO-C8:               config.full_width = 12 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "C"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_3_:%.+]] = tosa.reshape [[VAR_arg1_]] {new_shape = array<i64: 13, 21, 3, 4>} : (tensor<13x21x12xbf16>) -> tensor<13x21x3x4xbf16>
// CHECK-NO-C8:             [[VAR_4_:%.+]] = tosa.reduce_min [[VAR_3_]] {axis = 1 : i32} : (tensor<13x21x3x4xbf16>) -> tensor<13x1x3x4xbf16>
// CHECK-NO-C8:             [[VAR_5_:%.+]] = tosa.reshape [[VAR_4_]] {new_shape = array<i64: 13, 1, 12>} : (tensor<13x1x3x4xbf16>) -> tensor<13x1x12xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_5_]] : tensor<13x1x12xbf16>
// CHECK-NO-C8:           } -> tensor<13x1x12xbf16>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = tosa.reshape [[VAR_1_]] {new_shape = array<i64: 13, 1, 3, 4>} : (tensor<13x1x12xbf16>) -> tensor<13x1x3x4xbf16>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<13x1x3x4xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_bf16_4D_axis_2
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3x4xbf16>) -> tensor<13x21x1x4xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = tosa.reshape [[PARAM_0_]] {new_shape = array<i64: 273, 3, 4>} : (tensor<13x21x3x4xbf16>) -> tensor<273x3x4xbf16>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[VAR_0_]]: tensor<273x3x4xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 3 : ui32,
// CHECK-NO-C8:               config.full_height = 273 : ui32,
// CHECK-NO-C8:               config.full_width = 4 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "C"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_3_:%.+]] = tosa.reshape [[VAR_arg1_]] {new_shape = array<i64: 13, 21, 3, 4>} : (tensor<273x3x4xbf16>) -> tensor<13x21x3x4xbf16>
// CHECK-NO-C8:             [[VAR_4_:%.+]] = tosa.reduce_min [[VAR_3_]] {axis = 2 : i32} : (tensor<13x21x3x4xbf16>) -> tensor<13x21x1x4xbf16>
// CHECK-NO-C8:             [[VAR_5_:%.+]] = tosa.reshape [[VAR_4_]] {new_shape = array<i64: 273, 1, 4>} : (tensor<13x21x1x4xbf16>) -> tensor<273x1x4xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_5_]] : tensor<273x1x4xbf16>
// CHECK-NO-C8:           } -> tensor<273x1x4xbf16>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = tosa.reshape [[VAR_1_]] {new_shape = array<i64: 13, 21, 1, 4>} : (tensor<273x1x4xbf16>) -> tensor<13x21x1x4xbf16>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<13x21x1x4xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_bf16_4D_axis_3
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3x4xbf16>) -> tensor<13x21x3x1xbf16> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = tosa.reshape [[PARAM_0_]] {new_shape = array<i64: 273, 3, 4>} : (tensor<13x21x3x4xbf16>) -> tensor<273x3x4xbf16>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = xten_nn.subgraph ([[VAR_arg1_:%.+]] = [[VAR_0_]]: tensor<273x3x4xbf16>)  attributes {
// CHECK-NO-C8:             LayerName = "",
// CHECK-NO-C8:             Operands = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ifm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             OutputName = "",
// CHECK-NO-C8:             PadValue = 0x7F80 : bf16,
// CHECK-NO-C8:             Reason = "MllibKernel",
// CHECK-NO-C8:             Results = [
// CHECK-NO-C8:               {
// CHECK-NO-C8:                 CurrentDataFormat = "HCW",
// CHECK-NO-C8:                 Port = "data_io.ofm"
// CHECK-NO-C8:               }
// CHECK-NO-C8:             ],
// CHECK-NO-C8:             Specializes = "ReduceMin",
// CHECK-NO-C8:             Traits = {
// CHECK-NO-C8:               Reduce = true
// CHECK-NO-C8:             },
// CHECK-NO-C8:             With = {
// CHECK-NO-C8:               config.aie_arch = "aie-ml",
// CHECK-NO-C8:               config.dtype = "bfloat16",
// CHECK-NO-C8:               config.full_channel = 3 : ui32,
// CHECK-NO-C8:               config.full_height = 273 : ui32,
// CHECK-NO-C8:               config.full_width = 4 : ui32,
// CHECK-NO-C8:               config.reduce_dim = "W"
// CHECK-NO-C8:             }} {
// CHECK-NO-C8:             [[VAR_3_:%.+]] = tosa.reshape [[VAR_arg1_]] {new_shape = array<i64: 13, 21, 3, 4>} : (tensor<273x3x4xbf16>) -> tensor<13x21x3x4xbf16>
// CHECK-NO-C8:             [[VAR_4_:%.+]] = tosa.reduce_min [[VAR_3_]] {axis = 3 : i32} : (tensor<13x21x3x4xbf16>) -> tensor<13x21x3x1xbf16>
// CHECK-NO-C8:             [[VAR_5_:%.+]] = tosa.reshape [[VAR_4_]] {new_shape = array<i64: 273, 3, 1>} : (tensor<13x21x3x1xbf16>) -> tensor<273x3x1xbf16>
// CHECK-NO-C8:             xten_nn.output [[VAR_5_]] : tensor<273x3x1xbf16>
// CHECK-NO-C8:           } -> tensor<273x3x1xbf16>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = tosa.reshape [[VAR_1_]] {new_shape = array<i64: 13, 21, 3, 1>} : (tensor<273x3x1xbf16>) -> tensor<13x21x3x1xbf16>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<13x21x3x1xbf16>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_reduce_min_i8_annotations
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3xi8>) -> tensor<1x21x3xi8> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = xten_nn.dequantize([[PARAM_0_]] : tensor<13x21x3xi8>) {shift = 0 : si32} -> tensor<13x21x3xf32>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = tosa.reduce_min [[VAR_0_]] {
// CHECK-NO-C8:             LayerName = "LAYERNAME",
// CHECK-NO-C8:             OutputName = "OUTPUTNAME",
// CHECK-NO-C8:             axis = 0 : i32} : (tensor<13x21x3xf32>) -> tensor<1x21x3xf32>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = xten_nn.quantize([[VAR_1_]] : tensor<1x21x3xf32>) {shift = 0 : si32} -> tensor<1x21x3xi8>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<1x21x3xi8>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_i8_3D
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<1x13x21x3xi8>) -> tensor<1x13x21x1xi8> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = xten_nn.dequantize([[PARAM_0_]] : tensor<1x13x21x3xi8>) {shift = 0 : si32} -> tensor<1x13x21x3xf32>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = tosa.reduce_min [[VAR_0_]] {axis = 3 : i32} : (tensor<1x13x21x3xf32>) -> tensor<1x13x21x1xf32>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = xten_nn.quantize([[VAR_1_]] : tensor<1x13x21x1xf32>) {shift = 0 : si32} -> tensor<1x13x21x1xi8>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<1x13x21x1xi8>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_i8_2D
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21xi8>) -> tensor<1x21xi8> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = xten_nn.dequantize([[PARAM_0_]] : tensor<13x21xi8>) {shift = 0 : si32} -> tensor<13x21xf32>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = tosa.reduce_min [[VAR_0_]] {axis = 0 : i32} : (tensor<13x21xf32>) -> tensor<1x21xf32>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = xten_nn.quantize([[VAR_1_]] : tensor<1x21xf32>) {shift = 0 : si32} -> tensor<1x21xi8>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<1x21xi8>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_i8_4D_axis_0
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3x4xi8>) -> tensor<1x21x3x4xi8> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = xten_nn.dequantize([[PARAM_0_]] : tensor<13x21x3x4xi8>) {shift = 0 : si32} -> tensor<13x21x3x4xf32>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = tosa.reduce_min [[VAR_0_]] {axis = 0 : i32} : (tensor<13x21x3x4xf32>) -> tensor<1x21x3x4xf32>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = xten_nn.quantize([[VAR_1_]] : tensor<1x21x3x4xf32>) {shift = 0 : si32} -> tensor<1x21x3x4xi8>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<1x21x3x4xi8>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_i8_4D_axis_1
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3x4xi8>) -> tensor<13x1x3x4xi8> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = xten_nn.dequantize([[PARAM_0_]] : tensor<13x21x3x4xi8>) {shift = 0 : si32} -> tensor<13x21x3x4xf32>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = tosa.reduce_min [[VAR_0_]] {axis = 1 : i32} : (tensor<13x21x3x4xf32>) -> tensor<13x1x3x4xf32>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = xten_nn.quantize([[VAR_1_]] : tensor<13x1x3x4xf32>) {shift = 0 : si32} -> tensor<13x1x3x4xi8>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<13x1x3x4xi8>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_i8_4D_axis_2
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3x4xi8>) -> tensor<13x21x1x4xi8> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = xten_nn.dequantize([[PARAM_0_]] : tensor<13x21x3x4xi8>) {shift = 0 : si32} -> tensor<13x21x3x4xf32>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = tosa.reduce_min [[VAR_0_]] {axis = 2 : i32} : (tensor<13x21x3x4xf32>) -> tensor<13x21x1x4xf32>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = xten_nn.quantize([[VAR_1_]] : tensor<13x21x1x4xf32>) {shift = 0 : si32} -> tensor<13x21x1x4xi8>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<13x21x1x4xi8>
// CHECK-NO-C8:         }
// CHECK-NO-C8:         vaimlconf.device = "phx",
// CHECK-NO-C8:         vaimlconf.device_models = "${vaimlconf.install_dir}/third-party/aietools-interface/data",
// CHECK-NO-C8:         vaimlconf.install_dir = "/scratch/vitis_flexml_vs2/build",
// CHECK-NO-C8:         vaimlconf.library_metadata = ["${vaimlconf.install_dir}/../data/libraryMetadata/L1", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L1/metadata", "${vaimlconf.install_dir}/../data/libraryMetadata/L2", "${vaimlconf.install_dir}/../../venv3.10/lib/python3.10/site-packages/vitis_mllib/L2/metadata", "${vaimlconf.install_dir}/share/microkernel-tiling/tiling-recipe-specs"],
// CHECK-NO-C8:         vaimlconf.single_core_compiler = "chess"} {
// CHECK-NO-C8-LABEL:  func.func @test_any_reduce_i8_4D_axis_3
// CHECK-NO-C8-SAME:   ([[PARAM_0_:%.+]]: tensor<13x21x3x4xi8>) -> tensor<13x21x3x1xi8> {
// CHECK-NO-C8:           [[VAR_0_:%.+]] = xten_nn.dequantize([[PARAM_0_]] : tensor<13x21x3x4xi8>) {shift = 0 : si32} -> tensor<13x21x3x4xf32>
// CHECK-NO-C8:           [[VAR_1_:%.+]] = tosa.reduce_min [[VAR_0_]] {axis = 3 : i32} : (tensor<13x21x3x4xf32>) -> tensor<13x21x3x1xf32>
// CHECK-NO-C8:           [[VAR_2_:%.+]] = xten_nn.quantize([[VAR_1_]] : tensor<13x21x3x1xf32>) {shift = 0 : si32} -> tensor<13x21x3x1xi8>
// CHECK-NO-C8:           return [[VAR_2_]] : tensor<13x21x3x1xi8>
// CHECK-NO-C8:         }
