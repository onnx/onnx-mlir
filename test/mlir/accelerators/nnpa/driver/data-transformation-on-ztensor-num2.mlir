// RUN: onnx-mlir --maccel=NNPA --EmitMLIR --printIR %s | FileCheck %s

// -----

// Transpose will be done directly on stickified data, so no need to unstickify.
func.func @transpose_on_ztensor_unknown_dims(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %0 = "onnx.Relu" (%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
  %1 = "onnx.Transpose"(%0) {perm = [1,0]} : (tensor<?x?xf32>) -> tensor<?x?xf32>
  %2 = "onnx.Relu" (%1) : (tensor<?x?xf32>) -> tensor<?x?xf32>
  onnx.Return %2 : tensor<?x?xf32>

// CHECK-DAG:   [[MAP_0_:#.+]] = affine_map<()[s0] -> (s0 ceildiv 64)>
// CHECK-DAG:   [[MAP_1_:#.+]] = affine_map<()[s0] -> (s0 ceildiv 32)>

// CHECK-LABEL:  func.func @transpose_on_ztensor_unknown_dims
// CHECK-SAME:   ([[PARAM_0_:%.+]]: memref<?x?xf32>) -> memref<?x?xf32> attributes {llvm.emit_c_interface} {
// CHECK-DAG:       [[CST_1_:%.+]] = arith.constant 1 : index
// CHECK-DAG:       [[CST_0_:%.+]] = arith.constant 0 : index
// CHECK-NOT: separator of consecutive DAGs
// CHECK-DAG:       [[VAR_dim_:%.+]] = memref.dim [[PARAM_0_]], [[CST_0_]] : memref<?x?xf32>
// CHECK-DAG:       [[VAR_dim_0_:%.+]] = memref.dim [[PARAM_0_]], [[CST_1_]] : memref<?x?xf32>
// CHECK-NOT: separator of consecutive DAGs
// CHECK-DAG:       [[VAR_0_:%.+]] = affine.apply [[MAP_0_]](){{.}}[[VAR_dim_0_]]{{.}}
// CHECK-DAG:       [[VAR_1_:%.+]] = affine.apply [[MAP_1_]](){{.}}[[VAR_dim_]]{{.}}
// CHECK:           [[RES_:%.+]] = memref.alloc([[VAR_0_]], [[VAR_1_]]) {{.*}}: memref<1x?x1x?x32x64xf16>
// CHECK:           [[VAR_cast_:%.+]] = memref.cast [[RES_]] : memref<1x?x1x?x32x64xf16> to memref<1x?x1x?x?x?xf16>
// CHECK:           "zlow.stick"([[PARAM_0_]], [[VAR_cast_]]) {layout = "2D"} : (memref<?x?xf32>, memref<1x?x1x?x?x?xf16>) -> ()
// CHECK-DAG:       [[VAR_2_:%.+]] = affine.apply [[MAP_0_]](){{.}}[[VAR_dim_0_]]{{.}}
// CHECK-DAG:       [[VAR_3_:%.+]] = affine.apply [[MAP_1_]](){{.}}[[VAR_dim_]]{{.}}
// CHECK:           [[RES_1_:%.+]] = memref.alloc([[VAR_2_]], [[VAR_3_]]) {{.*}}: memref<1x?x1x?x32x64xf16>
// CHECK-DAG:       [[VAR_cast_2_:%.+]] = memref.cast [[RES_1_]] : memref<1x?x1x?x32x64xf16> to memref<1x?x1x?x?x?xf16>
// CHECK-DAG:       [[RES_2_:%.+]] = memref.alloc() {{.*}}: memref<2xi64>
// CHECK-DAG:       [[VAR_4_:%.+]] = arith.index_cast [[VAR_dim_]] : index to i64
// CHECK:           affine.store [[VAR_4_]], [[RES_2_]][0] : memref<2xi64>
// CHECK:           [[VAR_5_:%.+]] = arith.index_cast [[VAR_dim_0_]] : index to i64
// CHECK:           affine.store [[VAR_5_]], [[RES_2_]][1] : memref<2xi64>
// CHECK:           "zlow.relu"([[VAR_cast_]], [[RES_2_]], [[VAR_cast_]]_2) {layout = "2D"} : (memref<1x?x1x?x?x?xf16>, memref<2xi64>, memref<1x?x1x?x?x?xf16>) -> ()
// CHECK-DAG:       [[VAR_6_:%.+]] = affine.apply [[MAP_0_]](){{.}}[[VAR_dim_]]{{.}}
// CHECK-DAG:       [[VAR_7_:%.+]] = affine.apply [[MAP_1_]](){{.}}[[VAR_dim_0_]]{{.}}
// CHECK:           [[RES_3_:%.+]] = memref.alloc([[VAR_6_]], [[VAR_7_]]) {{.*}}: memref<1x?x1x?x32x64xf16>
// CHECK:           [[VAR_cast_5_:%.+]] = memref.cast [[RES_3_]] : memref<1x?x1x?x32x64xf16> to memref<1x?x1x?x?x?xf16>
// CHECK:           affine.for [[I_0_:%.+]] = 0 to [[VAR_dim_]] {
// CHECK:             affine.for [[I_1_:%.+]] = 0 to [[VAR_dim_0_]] {
// CHECK:               [[LOAD_RES_1_MEM_:%.+]] = affine.load [[RES_1_]][0, [[I_1_]] floordiv 64, 0, [[I_0_]] floordiv 32, [[I_0_]] mod 32, [[I_1_]] mod 64] : memref<1x?x1x?x32x64xf16>
// CHECK:               affine.store [[LOAD_RES_1_MEM_]], [[RES_3_]][0, [[I_0_]] floordiv 64, 0, [[I_1_]] floordiv 32, [[I_1_]] mod 32, [[I_0_]] mod 64] : memref<1x?x1x?x32x64xf16>
// CHECK:             }
// CHECK:           }
// CHECK-DAG:       [[VAR_8_:%.+]] = affine.apply [[MAP_0_]](){{.}}[[VAR_dim_]]{{.}}
// CHECK-DAG:       [[VAR_9_:%.+]] = affine.apply [[MAP_1_]](){{.}}[[VAR_dim_0_]]{{.}}
// CHECK:           [[RES_4_:%.+]] = memref.alloc([[VAR_8_]], [[VAR_9_]]) {{.*}}: memref<1x?x1x?x32x64xf16>
// CHECK-DAG:       [[VAR_cast_7_:%.+]] = memref.cast [[RES_4_]] : memref<1x?x1x?x32x64xf16> to memref<1x?x1x?x?x?xf16>
// CHECK-DAG:       [[RES_5_:%.+]] = memref.alloc() {{.*}}: memref<2xi64>
// CHECK-DAG:       [[VAR_10_:%.+]] = arith.index_cast [[VAR_dim_0_]] : index to i64
// CHECK:           affine.store [[VAR_10_]], [[RES_5_]][0] : memref<2xi64>
// CHECK:           [[VAR_11_:%.+]] = arith.index_cast [[VAR_dim_]] : index to i64
// CHECK:           affine.store [[VAR_11_]], [[RES_5_]][1] : memref<2xi64>
// CHECK:           "zlow.relu"([[VAR_cast_5_]], [[RES_5_]], [[VAR_cast_7_]]) {layout = "2D"} : (memref<1x?x1x?x?x?xf16>, memref<2xi64>, memref<1x?x1x?x?x?xf16>) -> ()
// CHECK:           [[RES_6_:%.+]] = memref.alloc([[VAR_dim_0_]], [[VAR_dim_]]) {{.*}}: memref<?x?xf32>
// CHECK:           "zlow.unstick"([[VAR_cast_7_]], [[RES_6_]]) {layout = "2D"} : (memref<1x?x1x?x?x?xf16>, memref<?x?xf32>) -> ()
// CHECK:           return [[RES_6_]] : memref<?x?xf32>
// CHECK:         }
}
